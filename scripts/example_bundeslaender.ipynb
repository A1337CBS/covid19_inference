{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time as time_module\n",
    "import sys\n",
    "import os \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "import theano\n",
    "import matplotlib\n",
    "import pymc3 as pm\n",
    "import theano.tensor as tt\n",
    "\n",
    "try: \n",
    "    import covid19_inference as cov19\n",
    "except ModuleNotFoundError:\n",
    "    sys.path.append('..')\n",
    "    import covid19_inference as cov19\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load the desired data from a source we also need to tell the class to download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO     [covid19_inference.data_retrieval] Loading local file.\n",
      "INFO     [covid19_inference.data_retrieval] Downloading new dataset from repository since it is newer.\n",
      "INFO     [covid19_inference.data_retrieval] Overwriting /data/rki_fallback_gzip.dat fallback with newest downloaded ones\n"
     ]
    }
   ],
   "source": [
    "rki = cov19.data_retrieval.RKI(True)\n",
    "#rki.download_all_available_data() #True argument above does this\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait for the download to finish. It will print a message!\n",
    "\n",
    "We can now access this downloaded data by the attribute but normaly one would use the build in filter methods.\n",
    "```\n",
    "rki.data\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bundeslaender = rki.filter_all_bundesland('2020-03-10', '2020-04-19')\n",
    "new_cases_obs = np.diff(np.array(df_bundeslaender),axis=0)[:,:]\n",
    "\n",
    "\n",
    "date_begin_data = datetime.datetime(2020,3,10)\n",
    "date_end_data   = datetime.datetime(2020,4,19)\n",
    "diff_data_sim = 16 # should be significantly larger than the expected delay, in \n",
    "                   # order to always fit the same number of data points.\n",
    "num_days_forecast = 10\n",
    "\n",
    "prior_date_mild_dist_begin =  datetime.datetime(2020,3,11)\n",
    "prior_date_strong_dist_begin =  datetime.datetime(2020,3,18)\n",
    "prior_date_contact_ban_begin =  datetime.datetime(2020,3,25)\n",
    "\n",
    "\n",
    "change_points = [dict(pr_mean_date_transient = prior_date_mild_dist_begin,\n",
    "                      pr_sigma_date_transient = 1.5,\n",
    "                      pr_median_lambda = 0.2,\n",
    "                      pr_sigma_lambda = 0.5,\n",
    "                     pr_sigma_transient_len=0.5),\n",
    "                 dict(pr_mean_date_transient = prior_date_strong_dist_begin,\n",
    "                      pr_sigma_date_transient = 1.5,\n",
    "                      pr_median_lambda = 1/8,\n",
    "                      pr_sigma_lambda = 0.5,\n",
    "                     pr_sigma_transient_len=0.5),\n",
    "                 dict(pr_mean_date_transient = prior_date_contact_ban_begin,\n",
    "                      pr_sigma_date_transient = 1.5,\n",
    "                      pr_median_lambda = 1/8/2,\n",
    "                      pr_sigma_lambda = 0.5,\n",
    "                     pr_sigma_transient_len=0.5)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO     [covid19_inference.model_helper] pr_median_transient_len was set to default value 4\n",
      "INFO     [covid19_inference.model_helper] pr_median_transient_len was set to default value 4\n",
      "INFO     [covid19_inference.model_helper] pr_median_transient_len was set to default value 4\n",
      "WARNING (theano.tensor.blas): We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n",
      "WARNING  [theano.tensor.blas] We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n"
     ]
    }
   ],
   "source": [
    "params_model = dict(new_cases_obs = new_cases_obs[:],\n",
    "                    data_begin = date_begin_data,\n",
    "                    fcast_len = num_days_forecast,\n",
    "                    diff_data_sim = diff_data_sim,\n",
    "                    N_population = 83e6) \n",
    "# normally one would put as N_population an array with the number of inhabitants of \n",
    "# of each state\n",
    "\n",
    "with cov19.Cov19Model(**params_model) as model:\n",
    "    lambda_t_log = cov19.lambda_t_with_sigmoids(pr_median_lambda_0 = 0.4, pr_sigma_lambda_0 = 0.5,\n",
    "                                                change_points_list = change_points)\n",
    "    \n",
    "    new_I_t = cov19.SIR(lambda_t_log, pr_median_mu=1/8, pr_beta_I_begin=20)\n",
    "    \n",
    "    new_cases_inferred_raw = cov19.delay_cases(new_I_t, pr_median_delay=10, \n",
    "                                               pr_median_scale_delay=0.3)\n",
    "    \n",
    "    new_cases_inferred = cov19.week_modulation(new_cases_inferred_raw)\n",
    "    \n",
    "    cov19.student_t_likelihood(new_cases_inferred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "INFO     [pymc3] Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi+adapt_diag...\n",
      "INFO     [pymc3] Initializing NUTS using advi+adapt_diag...\n",
      "Average Loss = 3,349.2:  25%|██▍       | 49899/200000 [02:21<07:04, 353.55it/s]\n",
      "Convergence achieved at 49900\n",
      "INFO     [pymc3.variational.inference] Convergence achieved at 49900\n",
      "Interrupted at 49,899 [24%]: Average Loss = 3,951.8\n",
      "INFO     [pymc3.variational.inference] Interrupted at 49,899 [24%]: Average Loss = 3,951.8\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "INFO     [pymc3] Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [sigma_obs, offset_modulation_rad, weekend_factor_L2_raw, weekend_factor_L1, sigma_weekend_factor_L2, delay_log_L2_raw, delay_log_L1, sigma_delay_L2, I_begin, mu, transient_len_3_log_L2_raw, transient_len_3_log_L1, sigma_transient_len_3_L2, transient_len_2_log_L2_raw, transient_len_2_log_L1, sigma_transient_len_2_L2, transient_len_1_log_L2_raw, transient_len_1_log_L1, sigma_transient_len_1_L2, transient_day_3_L2_raw, transient_day_3_L1, sigma_transient_day_3_L2, transient_day_2_L2_raw, transient_day_2_L1, sigma_transient_day_2_L2, transient_day_1_L2_raw, transient_day_1_L1, sigma_transient_day_1_L2, lambda_3_log_L2_raw, lambda_3_log_L1, sigma_lambda_3_L2, lambda_2_log_L2_raw, lambda_2_log_L1, sigma_lambda_2_L2, lambda_1_log_L2_raw, lambda_1_log_L1, sigma_lambda_1_L2, lambda_0_log_L2_raw, lambda_0_log_L1, sigma_lambda_0_L2]\n",
      "INFO     [pymc3] NUTS: [sigma_obs, offset_modulation_rad, weekend_factor_L2_raw, weekend_factor_L1, sigma_weekend_factor_L2, delay_log_L2_raw, delay_log_L1, sigma_delay_L2, I_begin, mu, transient_len_3_log_L2_raw, transient_len_3_log_L1, sigma_transient_len_3_L2, transient_len_2_log_L2_raw, transient_len_2_log_L1, sigma_transient_len_2_L2, transient_len_1_log_L2_raw, transient_len_1_log_L1, sigma_transient_len_1_L2, transient_day_3_L2_raw, transient_day_3_L1, sigma_transient_day_3_L2, transient_day_2_L2_raw, transient_day_2_L1, sigma_transient_day_2_L2, transient_day_1_L2_raw, transient_day_1_L1, sigma_transient_day_1_L2, lambda_3_log_L2_raw, lambda_3_log_L1, sigma_lambda_3_L2, lambda_2_log_L2_raw, lambda_2_log_L1, sigma_lambda_2_L2, lambda_1_log_L2_raw, lambda_1_log_L1, sigma_lambda_1_L2, lambda_0_log_L2_raw, lambda_0_log_L1, sigma_lambda_0_L2]\n",
      "Sampling 4 chains, 1 divergences:  52%|█████▏    | 4187/8000 [15:52<11:30,  5.52draws/s]"
     ]
    }
   ],
   "source": [
    "trace = pm.sample(model=model, tune=1000, draws=1000, init='advi+adapt_diag')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot\n",
    "We first define the x range on which we want to plot and create a datetime array for that range. Should be within the simulation period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd = datetime.datetime(2020,3,10)\n",
    "ed = datetime.datetime(2020,4,19) + datetime.timedelta(days=num_days_forecast)\n",
    "x = pd.date_range(bd,ed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we have to get our trace corresponding to that date range. We do that by calling the helper function `cov19.plot._get_array_from_trace_via_date()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = cov19.plot._get_array_from_trace_via_date(model,trace[\"lambda_t\"],x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on which trace variable we want to plot we have to look at the shape and maybe reshape it to match date length. Also the plot function wants a one dimensional array.\n",
    "\n",
    "After that we plot the timeseries. And set the format of the date axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.reshape()\n",
    "ax = cov19.plot._timeseries(x,y)\n",
    "cov19.plot.format_date_xticks(ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varnames = cov19.plotting.get_all_free_RVs_names(model)\n",
    "num_cols = 5\n",
    "num_rows = int(np.ceil(len(varnames)/num_cols))\n",
    "x_size = num_cols * 2.5\n",
    "y_size = num_rows * 2.5\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize = (x_size, y_size),squeeze=False)\n",
    "i_ax = 0\n",
    "for i_row, axes_row in enumerate(axes):\n",
    "    for i_col, ax in enumerate(axes_row):\n",
    "        if i_ax >= len(varnames):\n",
    "            ax.set_visible(False)\n",
    "            continue \n",
    "        else:\n",
    "            cov19.plotting.plot_hist(model, trace, ax, varnames[i_ax], \n",
    "                                     colors=('tab:blue', 'tab:green'))\n",
    "        if not i_col == 0:\n",
    "            ax.set_ylabel('')\n",
    "        if i_col == 0 and i_row == 0:\n",
    "            ax.legend()\n",
    "        i_ax += 1\n",
    "fig.subplots_adjust(wspace=0.25, hspace=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var_name in ['lambda_0_L2', 'lambda_1_L2', 'lambda_2_L2', 'lambda_3_L2',\n",
    "                 'transient_day_1_L2', 'transient_day_2_L2', 'transient_day_3_L2', 'delay_L2']:\n",
    "    f, ax = plt.subplots()\n",
    "    ax.violinplot(trace[var_name], showextrema=False, vert=False)\n",
    "    ax.set_yticks(np.arange(1,17))\n",
    "    ax.set_yticklabels(df_bundeslaender.columns)\n",
    "    ax.set_xlabel(var_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
